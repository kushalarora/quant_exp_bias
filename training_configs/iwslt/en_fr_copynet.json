{
  "dataset_reader": {
    "type": "seq2seq",
    "source_token_indexers": {
      "tokens": {
        "type": "single_id",
        "namespace": "source_tokens"
      },
      "token_characters": {
        "type": "characters"
      }
    },
    "target_token_indexers": {
      "tokens": {
        "namespace": "target_tokens"
      }
    }
  },
  "vocabulary": {
    "max_vocab_size": { 
        "source_tokens": 16000, 
        "target": 80000 
    }
  },
  "train_data_path": "data/wmt/english_to_french_train.tsv",
  "validation_data_path": "data/wmt/english_to_french_dev.tsv",
  // "train_data_path": "data/toy/seq2seq_copy.tsv",
  // "validation_data_path": "data/toy/seq2seq_copy.tsv",
  "model": {
    "type": "quant_exp_seq2seq",
    "target_namespace": "target_tokens",
    "target_output_dim": 300, 
    "target_embedding_dim": 50,
    "generation_batch_size": 32, 
    "max_decoding_steps": 50,
    "beam_size": 5,
    "use_bleu": true,
    "source_embedder": {
      "tokens": {
        "type": "embedding",
        "vocab_namespace": "source_tokens",
        "embedding_dim": 50,
        "pretrained_file": "https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.50d.txt.gz",
        "trainable": true
      },
      "token_characters": {
        "type": "character_encoding",
        "embedding": {
          "embedding_dim": 15
        },
        "encoder": {
          "type": "lstm",
          "input_size": 15,
          "hidden_size": 25,
          "num_layers": 2,
          "dropout": 0,
          "bidirectional": true
        }
      }
    },
    "encoder": {
      "type": "lstm",
      "input_size": 100,
      "hidden_size": 200,
      "num_layers": 2,
      "dropout": 0,
      "bidirectional": true
    },
    "attention": {
      "type": "bilinear",
      "vector_dim": 400,
      "matrix_dim": 400
    },
  },
  "iterator": {
    "type": "bucket",
    "padding_noise": 0.0,
    "batch_size" : 128,
    "sorting_keys": [["source_tokens", "num_tokens"]],
    "instances_per_epoch": 100000,
    "max_instances_in_memory": 10000
  },
  "trainer": {
    "num_epochs": 80,
    "patience": 10,
    "cuda_device": 0,
    "optimizer": {
      "type": "sgd",
      "lr": 0.01
    },
    "learning_rate_scheduler": {
      "type": "cosine",
      "t_initial": 5,
      "t_mul": 1.5,
      "eta_mul": 0.9
    },
    "should_log_learning_rate": true,
    "should_log_parameter_statistics": false
  }
}
