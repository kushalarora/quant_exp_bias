from typing import Dict, Optional, Tuple, Union, List

from fairseq.bleu import Scorer, SacrebleuScorer
from overrides import overrides

import torch

from quant_exp_bias.modules.cost_functions import CostFunction

@CostFunction.register("bleu")
class BLEUCostFunction(CostFunction):
    """ This call computes BLEU loss function between prediction and 
        gold targets. This is used to train NMT model.
    """

    def __init__(self, 
                 pad_token,
                 eos_token,
                 unk_token,
                 use_decoded_inputs = False,
                 ):

        if use_decoded_inputs:
            self._scorer = Scorer(pad_token,    
                                eos_token,
                                unk_token)
        else:
            self._scorer = SacrebleuScorer()

        self._use_decoded_inputs = use_decoded_inputs
  
    def __call__(self,
                 predictions: torch.Tensor,
                 gold_labels: torch.Tensor = None,
                 mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Parameters
        ----------
        predictions : ``torch.Tensor``, required.
            A tensor of predictions of shape (batch_size, ...).
        gold_labels : ``torch.Tensor``, required.
            A tensor of the same shape as ``predictions``.
        mask: ``torch.Tensor``, optional (default = None).
            A tensor of the same shape as ``predictions``.
        """
        predictions, gold_labels, mask = self.unwrap_to_tensors(predictions, gold_labels, mask)
        
        bleu_cost = -1 * self._scorer.add(gold_labels, predictions).score()
        self._scorer.reset()
        return bleu_cost

    def __call__(self,
                 predictions: List[str],
                 gold_labels: List[str] = None) -> torch.Tensor:

        """ Computes cost under oracle and returns the batch cost.
        
        Arguments:
            predictions {List[str]} -- predictions generated by a rollout.
            gold_labels {List[str]} -- Orignal Sequence.
        """
        total_count = 0
        for ref, pred  in zip(gold_labels, predictions):
            self._scorer.add_string(ref, pred)
            total_count += 1

        cost =  -1 * torch.tensor(self._scorer.score() + 1e-45).to(torch.cuda.current_device())/total_count
        
        self._scorer.reset()
        return cost

    @overrides
    def takes_decoded_input(self):
        return self._use_decoded_inputs