from typing import Dict, Optional, Tuple, Union, List

from overrides import overrides

from quant_exp_bias.modules.cost_functions.cost_function import CostFunction
from quant_exp_bias.oracles.oracle_base import Oracle

import logging
import torch

@CostFunction.register("noisy_oracle")
class NoiseOracleCostFunction(CostFunction):
    """This cost function computes the cost(negative likelihood) of predicted sequence under oracle and 
        returns a cost corrputed by noise. 
    """
    name: str = "noisy_oracle_cf"
    def __init__(self, 
                 oracle: Oracle, 
                 noise_type=None) -> None:
        self._oracle = oracle
        self._noise_type = noise_type

        if self._noise_type is not None:
            # Figure out how to add noise.
            pass
   
    def __call__(self,
                 predictions: List[str],
                 gold_labels: List[str] = None) -> torch.Tensor:

        """ Computes cost under oracle and returns the batch cost.

        Arguments:
            predictions {List[str]} -- predictions generated by a rollout.
            gold_labels {List[str]} -- Orignal Sequence.

        """

        # This hack given 0 oracle prob to sequences of length 1. 
        # This is done as GPT2 craches for length 1 sequences.

        filtered_predictions = []
        old2new = {}
        for i, prediction in enumerate(predictions):
            if len(prediction) > 1:
                old2new[i] = len(filtered_predictions)
                filtered_predictions.append(prediction)

        filtered_oracle_probs = self._oracle.compute_sent_probs(filtered_predictions)

        oracle_probs = []
        j = 0
        for i, prediction in enumerate(predictions):
            if i in old2new:
                oracle_probs.append(filtered_oracle_probs[j])
                j += 1
            else:
                oracle_probs.append(0)

        # We return neg log prob.
        # The objective should be minimize this cost to 0.
        return -1 * torch.log(torch.cuda.FloatTensor(oracle_probs)+ 1e-45).to(torch.cuda.current_device())

    @overrides
    def takes_decoded_input(self):
        return True